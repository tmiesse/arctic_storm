{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Output Notebook\n",
    "\n",
    "<img style=\"float:center;\" src=\"https://arcticexpansion.vse.gmu.edu/sites/arcticexpansion.vsnet.gmu.edu/files/images/header5d2.png\" width=600px>\n",
    "\n",
    "### ADCIRC-SWAN Output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc4;\n",
    "import pathlib as pl;     \n",
    "import numpy as np   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source $HOME/miniforge3/bin/activate\n",
    "\n",
    "salloc --ntasks=5 --nodes=1 --partition=normal --time=10:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data for this exercise can be found here\n",
    "https://doi.org/10.17603/ds2-h0fw-2p96\n",
    "\n",
    "Download the swan_HS.63.nc from one of the 4 folders\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_ROOT = pl.Path('/groups/ORC-CLIMATE/fhrl_repo/Arctic_Database/Raw_DATA')\n",
    "OUTPUT_ROOT = pl.Path('/scratch/tmiesse/project/data4spatial')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2024 → /scratch/tmiesse/project/data4spatial/2024/fort.63.cf.nc\n"
     ]
    }
   ],
   "source": [
    "YEARS       = [2023]#2021,2020,2019,2018,2017,2016,2015,\n",
    "               #2014,2013,2012,2011,2010,2009,2008,\n",
    "               #2007,2006,2005,2004,2003,2002,2001,\n",
    "               #2000,1999,1998,1997,1996,1995,1994,\n",
    "               #1993,1992,1991,1990]\n",
    "KEEP_VARS   = [\"time\", \"x\", \"y\", \"element\", \"zeta\", \"depth\"]\n",
    "\n",
    "# depth bounds\n",
    "MIN_DEPTH = 0.0\n",
    "MAX_DEPTH = 5.0\n",
    "\n",
    "for year in YEARS:\n",
    "    src_path = INPUT_ROOT / str(year) / \"outputs\" / \"fort.63.nc\"\n",
    "    if not src_path.exists():\n",
    "        print(f\"Skipping {year}: {src_path} not found\")\n",
    "        continue\n",
    "\n",
    "    out_dir  = OUTPUT_ROOT / str(year)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dst_path = out_dir / \"fort.63.cf.nc\"\n",
    "    print(f\"Processing {year} → {dst_path}\")\n",
    "\n",
    "    with nc4.Dataset(src_path, \"r\") as ds0:\n",
    "        # 0) pick off the depth array & compute keep_idx\n",
    "        depth_arr = ds0.variables[\"depth\"][:]  # (node,)\n",
    "        fv_depth  = getattr(ds0.variables[\"depth\"], \"_FillValue\", None)\n",
    "        # build mask of valid nodes\n",
    "        mask = np.ones_like(depth_arr, dtype=bool)\n",
    "        if fv_depth is not None:\n",
    "            mask &= (depth_arr != fv_depth)\n",
    "        mask &= (depth_arr >= MIN_DEPTH) & (depth_arr <= MAX_DEPTH)\n",
    "        keep_idx = np.nonzero(mask)[0]\n",
    "        n_node_new = keep_idx.size\n",
    "\n",
    "        # 1) read & filter connectivity (element → face_node_connectivity)\n",
    "        conn0 = ds0.variables[\"element\"][:]            # shape (nele, nvertex)\n",
    "        # find triangles fully in shallow nodes\n",
    "        tri_mask = np.all(np.isin(conn0, keep_idx), axis=1)\n",
    "        conn_filt = conn0[tri_mask, :]\n",
    "        # build map global->local\n",
    "        local_map = {g: i for i, g in enumerate(keep_idx)}\n",
    "        remap = np.vectorize(local_map.get)(conn_filt)\n",
    "        n_nele_new = remap.shape[0]\n",
    "\n",
    "        # 2) start new CF file\n",
    "        with nc4.Dataset(dst_path, \"w\") as ds1:\n",
    "            # 1) copy global attributes\n",
    "            ds1.setncatts({k: ds0.getncattr(k) for k in ds0.ncattrs()})\n",
    "\n",
    "            # 2) create dimensions\n",
    "            for name, dim in ds0.dimensions.items():\n",
    "                if name == \"node\":\n",
    "                    ds1.createDimension(\"node\", n_node_new)\n",
    "                elif name == \"nele\":\n",
    "                    ds1.createDimension(\"nele\", n_nele_new)\n",
    "                else:\n",
    "                    size = None if dim.isunlimited() else len(dim)\n",
    "                    ds1.createDimension(name, size)\n",
    "\n",
    "            # 3) copy all other variables except 'element'\n",
    "            KEEP_VARS = [\"time\", \"x\", \"y\", \"zeta\", \"depth\"]\n",
    "            for name in KEEP_VARS:\n",
    "                var0 = ds0.variables[name]\n",
    "                dims = var0.dimensions\n",
    "                fv   = getattr(var0, \"_FillValue\", None)\n",
    "\n",
    "                # create var in ds1\n",
    "                if fv is not None:\n",
    "                    var1 = ds1.createVariable(name, var0.datatype, dims, fill_value=fv)\n",
    "                else:\n",
    "                    var1 = ds1.createVariable(name, var0.datatype, dims)\n",
    "\n",
    "                # copy data, slicing on node if needed\n",
    "                if \"node\" in dims:\n",
    "                    idx = tuple(\n",
    "                        keep_idx if d == \"node\" else slice(None)\n",
    "                        for d in dims\n",
    "                    )\n",
    "                    var1[:] = var0[idx]\n",
    "                else:\n",
    "                    var1[:] = var0[:]\n",
    "\n",
    "                # copy attributes (except _FillValue)\n",
    "                for attr, val in var0.__dict__.items():\n",
    "                    if attr == \"_FillValue\":\n",
    "                        continue\n",
    "                    var1.setncattr(attr, val)\n",
    "\n",
    "            # 4) now write the filtered & remapped connectivity\n",
    "            conn_var = ds1.createVariable(\n",
    "                \"face_node_connectivity\",\n",
    "                remap.dtype,\n",
    "                (\"nele\", \"nvertex\")\n",
    "            )\n",
    "            conn_var[:] = remap\n",
    "            # copy attrs from original element var\n",
    "            for attr, val in ds0.variables[\"element\"].__dict__.items():\n",
    "                if attr == \"_FillValue\":\n",
    "                    continue\n",
    "                conn_var.setncattr(attr, val)\n",
    "            conn_var.setncattr(\"cf_role\", \"face_node_connectivity\")\n",
    "\n",
    "            # 5) define mesh topology\n",
    "            mesh = ds1.createVariable(\"mesh2d\", \"i4\", ())\n",
    "            mesh.setncattr(\"cf_role\", \"mesh_topology\")\n",
    "            mesh.setncattr(\"topology_dimension\", 2)\n",
    "            mesh.setncattr(\"node_coordinates\", \"x y\")\n",
    "            mesh.setncattr(\"face_node_connectivity\", \"face_node_connectivity\")\n",
    "\n",
    "    print(f\"  → Done {year}\")\n",
    "\n",
    "print(\"All years processed; CF‑ified, depth‑filtered files under:\", OUTPUT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 2021 → /scratch/tmiesse/project/data4spatial/2021/fort.63.cf.nc\n",
      "  → Done 2021\n",
      "Processing year 2020 → /scratch/tmiesse/project/data4spatial/2020/fort.63.cf.nc\n",
      "  → Done 2020\n",
      "Processing year 2019 → /scratch/tmiesse/project/data4spatial/2019/fort.63.cf.nc\n",
      "  → Done 2019\n",
      "Processing year 2018 → /scratch/tmiesse/project/data4spatial/2018/fort.63.cf.nc\n",
      "  → Done 2018\n",
      "Processing year 2017 → /scratch/tmiesse/project/data4spatial/2017/fort.63.cf.nc\n",
      "  → Done 2017\n",
      "Processing year 2016 → /scratch/tmiesse/project/data4spatial/2016/fort.63.cf.nc\n",
      "  → Done 2016\n",
      "Processing year 2015 → /scratch/tmiesse/project/data4spatial/2015/fort.63.cf.nc\n",
      "  → Done 2015\n",
      "Processing year 2014 → /scratch/tmiesse/project/data4spatial/2014/fort.63.cf.nc\n",
      "  → Done 2014\n",
      "Processing year 2013 → /scratch/tmiesse/project/data4spatial/2013/fort.63.cf.nc\n",
      "  → Done 2013\n",
      "Processing year 2012 → /scratch/tmiesse/project/data4spatial/2012/fort.63.cf.nc\n",
      "  → Done 2012\n",
      "Processing year 2011 → /scratch/tmiesse/project/data4spatial/2011/fort.63.cf.nc\n",
      "  → Done 2011\n",
      "Processing year 2010 → /scratch/tmiesse/project/data4spatial/2010/fort.63.cf.nc\n",
      "  → Done 2010\n",
      "Processing year 2009 → /scratch/tmiesse/project/data4spatial/2009/fort.63.cf.nc\n",
      "  → Done 2009\n",
      "Processing year 2008 → /scratch/tmiesse/project/data4spatial/2008/fort.63.cf.nc\n",
      "  → Done 2008\n",
      "Processing year 2007 → /scratch/tmiesse/project/data4spatial/2007/fort.63.cf.nc\n",
      "  → Done 2007\n",
      "Processing year 2006 → /scratch/tmiesse/project/data4spatial/2006/fort.63.cf.nc\n",
      "  → Done 2006\n",
      "Processing year 2005 → /scratch/tmiesse/project/data4spatial/2005/fort.63.cf.nc\n",
      "  → Done 2005\n",
      "Processing year 2004 → /scratch/tmiesse/project/data4spatial/2004/fort.63.cf.nc\n",
      "  → Done 2004\n",
      "Processing year 2003 → /scratch/tmiesse/project/data4spatial/2003/fort.63.cf.nc\n",
      "  → Done 2003\n",
      "Processing year 2002 → /scratch/tmiesse/project/data4spatial/2002/fort.63.cf.nc\n",
      "  → Done 2002\n",
      "Processing year 2001 → /scratch/tmiesse/project/data4spatial/2001/fort.63.cf.nc\n",
      "  → Done 2001\n",
      "Processing year 2000 → /scratch/tmiesse/project/data4spatial/2000/fort.63.cf.nc\n",
      "  → Done 2000\n",
      "Processing year 1999 → /scratch/tmiesse/project/data4spatial/1999/fort.63.cf.nc\n",
      "  → Done 1999\n",
      "Processing year 1998 → /scratch/tmiesse/project/data4spatial/1998/fort.63.cf.nc\n",
      "  → Done 1998\n",
      "Processing year 1997 → /scratch/tmiesse/project/data4spatial/1997/fort.63.cf.nc\n",
      "  → Done 1997\n",
      "Processing year 1996 → /scratch/tmiesse/project/data4spatial/1996/fort.63.cf.nc\n",
      "  → Done 1996\n",
      "Processing year 1995 → /scratch/tmiesse/project/data4spatial/1995/fort.63.cf.nc\n",
      "  → Done 1995\n",
      "Processing year 1994 → /scratch/tmiesse/project/data4spatial/1994/fort.63.cf.nc\n",
      "  → Done 1994\n",
      "Processing year 1993 → /scratch/tmiesse/project/data4spatial/1993/fort.63.cf.nc\n",
      "  → Done 1993\n",
      "Processing year 1992 → /scratch/tmiesse/project/data4spatial/1992/fort.63.cf.nc\n",
      "  → Done 1992\n",
      "Processing year 1991 → /scratch/tmiesse/project/data4spatial/1991/fort.63.cf.nc\n",
      "  → Done 1991\n",
      "Processing year 1990 → /scratch/tmiesse/project/data4spatial/1990/fort.63.cf.nc\n",
      "  → Done 1990\n",
      "All years processed. CF‑ified files are under: /scratch/tmiesse/project/data4spatial\n"
     ]
    }
   ],
   "source": [
    "YEARS = [2021,2020,2019,2018,2017,2016,2015,2014,2013,2012,2011,2010,\n",
    "         2009,2008,2007,2006,2005,2004,2003,2002,2001,2000,\n",
    "         1999,1998,1997,1996,1995,1994,1993,1992,1991,1990]\n",
    "KEEP_VARS = [\"time\", \"x\", \"y\", \"element\", \"zeta\", \"depth\"]\n",
    "for year in YEARS:\n",
    "    src_path = INPUT_ROOT / str(year) / 'outputs' / 'fort.63.nc'\n",
    "    if not src_path.exists():\n",
    "        print(f\"Skipping {year}: {src_path} not found\")\n",
    "        continue\n",
    "\n",
    "    # Prepare output directory for this year\n",
    "    out_dir = OUTPUT_ROOT / str(year)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dst_path = out_dir / 'fort.63.cf.nc'\n",
    "\n",
    "    print(f\"Processing year {year} → {dst_path}\")\n",
    "\n",
    "    with nc4.Dataset(src_path, 'r') as ds0, nc4.Dataset(dst_path, 'w') as ds1:\n",
    "        # 1) Copy global attributes\n",
    "        ds1.setncatts({k: ds0.getncattr(k) for k in ds0.ncattrs()})\n",
    "\n",
    "        # 2) Copy dimensions\n",
    "        for name, dim in ds0.dimensions.items():\n",
    "            ds1.createDimension(name, len(dim) if not dim.isunlimited() else None)\n",
    "\n",
    "        # 3) Copy selected variables, handling _FillValue\n",
    "        for name in KEEP_VARS:\n",
    "            var0 = ds0.variables[name]\n",
    "            out_name = \"face_node_connectivity\" if name == \"element\" else name\n",
    "\n",
    "            # Determine fill_value if present\n",
    "            fv = getattr(var0, \"_FillValue\", None)\n",
    "\n",
    "            # Create variable with fill_value if needed\n",
    "            if fv is not None:\n",
    "                var1 = ds1.createVariable(out_name,\n",
    "                                          var0.datatype,\n",
    "                                          var0.dimensions,\n",
    "                                          fill_value=fv)\n",
    "            else:\n",
    "                var1 = ds1.createVariable(out_name,\n",
    "                                          var0.datatype,\n",
    "                                          var0.dimensions)\n",
    "\n",
    "            # Copy the data\n",
    "            var1[:] = var0[:]\n",
    "\n",
    "            # Copy all attributes except _FillValue\n",
    "            for attr, val in var0.__dict__.items():\n",
    "                if attr == \"_FillValue\":\n",
    "                    continue\n",
    "                var1.setncattr(attr, val)\n",
    "\n",
    "            # Mark connectivity variable\n",
    "            if name == \"element\":\n",
    "                var1.setncattr(\"cf_role\", \"face_node_connectivity\")\n",
    "\n",
    "        # 4) Declare the mesh topology\n",
    "        mesh = ds1.createVariable(\"mesh2d\", \"i4\", ())\n",
    "        mesh.setncattr(\"cf_role\", \"mesh_topology\")\n",
    "        mesh.setncattr(\"topology_dimension\", 2)\n",
    "        mesh.setncattr(\"node_coordinates\", \"x y\")\n",
    "        mesh.setncattr(\"face_node_connectivity\", \"face_node_connectivity\")\n",
    "\n",
    "    print(f\"  → Done {year}\")\n",
    "\n",
    "print(\"All years processed. CF‑ified files are under:\", OUTPUT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
